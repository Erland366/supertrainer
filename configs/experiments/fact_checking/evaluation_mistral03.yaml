# @package _global_

defaults:
- /experiments/fact_checking/default_evaluation
- _self_

evaluation:
  peft_kwargs:
    r: 64
    lora_alpha: 128
    lora_dropout: 0.1
    target_modules:
      - 'down_proj'
      - 'o_proj'
      - 'k_proj'
      - 'q_proj'
      - 'gate_proj'
      - 'up_proj'
      - 'v_proj'
    use_dora: False
    init_lora_weights: "gaussian"

  class_name: supertrainer.evaluations.mistral03.Mistral03Evaluation
  model_name: unsloth/mistral-7b-instruct-v0.3-bnb-4bit
  chat_template: mistral

dataset:
  chat_template: mistral
