# @package _global_

defaults:
- /experiments/fact_checking/default_inference
- _self_

inference:
  peft_kwargs:
    r: 64
    lora_alpha: 128
    lora_dropout: 0.1
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
      - "gate_proj"
      - "up_proj"
      - "down_proj"

  class_name: supertrainer.inferences.llama32.Llama32NewTokenInference
  model_name: Erland/llama32-fact-checking-new_token_20241125_201759-without_lora-train_claim_arb_evidence_arb
  chat_template: llama-3.1

dataset:
  class2token:
    REFUTES: "<|CLASS_1|>"
    SUPPORTS: "<|CLASS_2|>"
    NOT_ENOUGH_INFO: "<|CLASS_3|>"
